# Projeto de ETL e An√°lise de Vendas para E-commerce

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?style=for-the-badge&logo=python)
![Pandas](https://img.shields.io/badge/Pandas-2.x-green?style=for-the-badge&logo=pandas)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-14-blue?style=for-the-badge&logo=postgresql)
![Status](https://img.shields.io/badge/Status-Conclu√≠do-brightgreen?style=for-the-badge)

<p align="center">
  <img src="images/top_10_qtd_vendida.PNG" width="800" alt="Top 10 Produtos Mais Vendidos por Quantidade">
</p>

## üìú Descri√ß√£o Geral

Este projeto simula um fluxo de trabalho de dados ponta a ponta, desde a ingest√£o de dados brutos at√© a gera√ß√£o de insights acion√°veis. O processo consiste em um pipeline de **ETL (Extra√ß√£o, Transforma√ß√£o e Carga)** que coleta dados de 7 fontes CSV distintas, os limpa, padroniza e carrega em um banco de dados PostgreSQL. Posteriormente, um notebook de an√°lise consome esses dados tratados para explorar o desempenho de vendas, identificar tend√™ncias e visualizar os principais indicadores de neg√≥cio.

**Etapa 1: Dados Brutos (/data/raw)**
O ponto de partida foram 7 arquivos CSV com origens e estruturas distintas. Os dados nesta fase apresentavam inconsist√™ncias como nomes de colunas sem padr√£o, formatos de data variados e tipos de dados mistos.

**Etapa 2: Script de ETL (pre_processamento.py)**
O script de pr√©-processamento foi desenvolvido para automatizar a limpeza. A cada execu√ß√£o, ele realiza as seguintes tarefas:
- **Extra√ß√£o:** L√™ os arquivos CSV padronizados da pasta /data/raw.
- **Transforma√ß√£o:** Aplica as regras de limpeza definidas na configura√ß√£o `FILE_CONFIG`, como padroniza√ß√£o de colunas para `snake_case`, convers√£o de datas e tratamento de dados faltantes.
- **Carga:** Carrega os DataFrames limpos em um banco de dados PostgreSQL, criando tabelas padronizadas (cln_...). Simultaneamente, salva uma c√≥pia dos arquivos limpos na pasta `/data/clean` para fins de portf√≥lio.

**Etapa 3: Banco de Dados (PostgreSQ)**
O PostgreSQL atua como a **fonte √∫nica da verdade** para a an√°lise. Armazenar os dados limpos em um banco de dados garante que a etapa de an√°lise seja desacoplada da limpeza, seguindo as melhores pr√°ticas de engenharia de dados.

**Etapa 4: An√°lise e Insights (analise.ipynb)**
O Jupyter Notebook de an√°lise conecta-se exclusivamente ao banco de dados para consumir os dados j√° tratados. √â nesta fase que os dados de diferentes fontes s√£o consolidados e as perguntas de neg√≥cio s√£o respondidas atrav√©s de agrega√ß√µes, c√°lculos e, finalmente, a cria√ß√£o dos gr√°ficos e a extra√ß√£o dos insights apresentados neste documento.

---

---

## ‚ú® Features Principais

- **Pipeline de ETL Robusto:** Um script Python automatizado que executa todo o processo de limpeza e carregamento de dados.
- **Limpeza e Padroniza√ß√£o:** Tratamento de dados faltantes, padroniza√ß√£o de nomes de colunas para o formato `snake_case` e convers√£o de tipos de dados (datas, n√∫meros).
- **Banco de Dados Centralizado:** Utiliza√ß√£o do PostgreSQL como uma "fonte √∫nica da verdade", armazenando os dados limpos em tabelas com prefixo `cln_` para f√°cil identifica√ß√£o.
- **An√°lise Consolidada:** Um Jupyter Notebook que une os dados de todas as fontes para criar uma vis√£o hol√≠stica do neg√≥cio.
- **Visualiza√ß√£o de Dados:** Gera√ß√£o de m√∫ltiplos gr√°ficos para responder perguntas de neg√≥cio chave, como:
  - Qual o faturamento mensal consolidado?
  - Quais os produtos mais vendidos por receita e por quantidade?
  - Quais as categorias de produtos mais lucrativas?

---

## üõ†Ô∏è Tecnologias Utilizadas

| Ferramenta | Prop√≥sito |
| :--- | :--- |
| **Python 3.9** | Linguagem principal para desenvolvimento do ETL e da an√°lise. |
| **Pandas** | Biblioteca fundamental para manipula√ß√£o e an√°lise dos dados. |
| **PostgreSQL** | Sistema de gerenciamento de banco de dados para armazenar os dados limpos. |
| **SQLAlchemy** | Biblioteca Python para conectar e interagir com o banco de dados. |
| **Matplotlib & Seaborn** | Bibliotecas para a cria√ß√£o das visualiza√ß√µes de dados. |
| **Jupyter Notebook** | Ambiente interativo para a an√°lise explorat√≥ria e apresenta√ß√£o dos resultados. |

---

## üéØ Desafios e Solu√ß√µes

Durante o desenvolvimento, alguns desafios interessantes surgiram, exigindo solu√ß√µes espec√≠ficas para garantir a qualidade dos dados.

| Desafio | Solu√ß√£o Implementada |
| :--- | :--- |
| **M√∫ltiplas Fontes de Dados** | Criei um dicion√°rio de configura√ß√£o (`FILE_CONFIG`) para gerenciar as regras de cada arquivo de forma centralizada, tornando o script modular e f√°cil de estender. |
| **Formatos de Data Inconsistentes** | A fun√ß√£o de ETL detecta formatos de data n√£o-padr√£o (ex: "Jun-21") e aplica a convers√£o correta, unificando tudo para o tipo `datetime`. |
| **Colunas com Nomes Diferentes** | Implementei uma fun√ß√£o de padroniza√ß√£o para converter todos os nomes de colunas para um formato `snake_case` consistente antes de carregar no banco de dados. |
| **Dados Num√©ricos como Texto** | No notebook de an√°lise, utilizei `pd.to_numeric` com `errors='coerce'` para for√ßar a convers√£o de colunas de faturamento, garantindo que valores n√£o-num√©ricos (ex: texto) n√£o quebrassem os c√°lculos. |

---

## üöÄ Como Executar o Projeto

Siga os passos abaixo para configurar e executar este projeto em seu ambiente local.

### 1. Pr√©-requisitos
- Python 3.9 ou superior
- PostgreSQL instalado e em execu√ß√£o.
- Git para clonar o reposit√≥rio.

### 2. Clonando o Reposit√≥rio
```bash
git clone [https://github.com/haykd7v/e-commerce_database.git](https://github.com/haykd7v/e-commerce_database.git)
cd e-commerce_database
```

### 3. Configura√ß√£o do Ambiente
√â altamente recomendado o uso de um ambiente virtual.
```bash
# Crie o ambiente virtual
python -m venv venv

# Ative o ambiente
# Windows
.\venv\Scripts\activate
# macOS / Linux
source venv/bin/activate
```

### 4. Instala√ß√£o das Depend√™ncias
Instale todas as bibliotecas necess√°rias com um √∫nico comando.
```bash
pip install -r requirements.txt
```

### 5. Configura√ß√£o do Banco de Dados
- Certifique-se de que seu servidor PostgreSQL esteja rodando.
- Crie um novo banco de dados chamado `ecommerce`.
- **Importante:** Verifique se as credenciais no script de ETL (`DB_ENGINE = create_engine(...)`) correspondem √†s suas (usu√°rio, senha, porta).

### 6. Execu√ß√£o
O projeto deve ser executado em duas etapas, nesta ordem:

**Etapa 1: Rodar o Pipeline de ETL**
Este script ir√° limpar os dados da pasta `/data/raw` e carreg√°-los no seu banco de dados PostgreSQL.
```bash
python preprocessamento.py
```

**Etapa 2: Rodar o Notebook de An√°lise**
Abra o Jupyter Notebook `analise.ipynb` para ver a an√°lise, os insights e os gr√°ficos gerados a partir dos dados limpos no banco.
```bash
jupyter notebook analise.ipynb
```

---

## üìÇ Estrutura do Reposit√≥rio
```
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îú‚îÄ‚îÄ raw/                # Cont√©m os 7 datasets originais e brutos.
‚îÇ   ‚îî‚îÄ‚îÄ clean/              # Onde os datasets limpos s√£o salvos em formato CSV.
‚îú‚îÄ‚îÄ images/                 # Cont√©m as imagens dos gr√°ficos para o README.
‚îú‚îÄ‚îÄ analise.ipynb           # Notebook com a an√°lise explorat√≥ria e visualiza√ß√µes.
‚îú‚îÄ‚îÄ preprocessamento.py     # Script principal de ETL.
‚îú‚îÄ‚îÄ requirements.txt        # Lista de depend√™ncias do projeto para f√°cil instala√ß√£o.
‚îî‚îÄ‚îÄ README.md               # Esta documenta√ß√£o.
```

---

## üìä Resultados e Insights
A an√°lise dos dados consolidados revelou os seguintes insights chave:
- **Insight 1:** O produto mais vendido em **faturamento** foi o **J0D20-SKD-M**, enquanto o mais vendido em **quantidade** foi o **JNE3797-KR-L**, indicando a import√¢ncia de produtos de menor valor para o volume de vendas.
- **Insight 2:** A categoria de **Kurta** √© a mais rent√°vel, respondendo por mais de **20%** do faturamento total analisado.

---

## üë®‚Äçüíª Autor

- **Wallace Magalh√£es**
- **LinkedIn:** [Meu Perfil no LinkedIn](https://www.linkedin.com/in/euwallacee1/)
- **GitHub:** [haykd7v](https://github.com/haykd7v)
